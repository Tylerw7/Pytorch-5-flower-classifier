{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4CIlxp1HoCqH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import os\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xaUtFI7pl6n",
        "outputId": "8f68e4c2-3469-43a6-fa9e-ae56729bc90f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flower Folder Path\n",
        "flower_images = '/content/drive/MyDrive/5_flower_classifier'"
      ],
      "metadata": {
        "id": "PQ1WmuWNuRaA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train set transformations\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((256,256)),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.RandomPerspective(distortion_scale=0.2, p=0.3),\n",
        "    transforms.ColorJitter(brightness=0.5,contrast=0.5,saturation=0.5,hue=0.1),\n",
        "    transforms.RandomGrayscale(p=0.1),\n",
        "    transforms.GaussianBlur(kernel_size=3,sigma=(0.1,2.0)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "# Validation set transformations\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "qUSf1GFMumaD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The code below was used to create a train and test set from my flower images."
      ],
      "metadata": {
        "id": "BqovM5Ls6w-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Path to original dataset\n",
        "src_folder = \"/content/drive/MyDrive/5_flower_classifier/flowers\"\n",
        "# Paths to output train/test folders\n",
        "train_folder = \"/content/drive/MyDrive/5_flower_classifier/train\"\n",
        "test_folder = \"/content/drive/MyDrive/5_flower_classifier/test\"\n",
        "\n",
        "# Create train/test folders\n",
        "os.makedirs(train_folder, exist_ok=True)\n",
        "os.makedirs(test_folder, exist_ok=True)\n",
        "\n",
        "# Set train/test split ratio\n",
        "train_ratio = 0.8  # 80% train, 20% test\n",
        "\n",
        "# Iterate through each class folder\n",
        "for class_name in os.listdir(src_folder):\n",
        "    class_path = os.path.join(src_folder, class_name)\n",
        "    if not os.path.isdir(class_path):\n",
        "        continue\n",
        "\n",
        "    images = os.listdir(class_path)\n",
        "    random.shuffle(images)  # shuffle images\n",
        "\n",
        "    split_index = int(len(images) * train_ratio)\n",
        "    train_images = images[:split_index]\n",
        "    test_images = images[split_index:]\n",
        "\n",
        "    # Create class folders in train/test directories\n",
        "    os.makedirs(os.path.join(train_folder, class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_folder, class_name), exist_ok=True)\n",
        "\n",
        "    # Move/copy images\n",
        "    for img in train_images:\n",
        "        shutil.copy(os.path.join(class_path, img), os.path.join(train_folder, class_name, img))\n",
        "    for img in test_images:\n",
        "        shutil.copy(os.path.join(class_path, img), os.path.join(test_folder, class_name, img))\n",
        "\n",
        "print(\"Dataset split completed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVvHi9tlxUon",
        "outputId": "dac6a551-d090-4d2e-ea27-94d86e8f38c7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the datasets for train and test\n",
        "train_dataset = datasets.ImageFolder(\"/content/drive/MyDrive/5_flower_classifier/train\", transform=train_transform)\n",
        "test_dataset = datasets.ImageFolder(\"/content/drive/MyDrive/5_flower_classifier/test\", transform=test_transform)"
      ],
      "metadata": {
        "id": "BZ7UboPIxe4g"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)"
      ],
      "metadata": {
        "id": "OiR2LaIl775I"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classes\n",
        "print(train_dataset.classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82kVdR2K8W6W",
        "outputId": "12e208b7-48c9-45e8-bff9-4e625376c0d2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining Model / Training"
      ],
      "metadata": {
        "id": "71fTTSGA8pAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet50(pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFK1d04G8j7Q",
        "outputId": "35c71ac9-07fb-4285-e778-e8005a9f9394"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 115MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of input features\n",
        "num_features = model.fc.in_features\n",
        "num_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZFoINR89S7n",
        "outputId": "b1d72b2f-1113-46c7-ea26-13bee0476beb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2048"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(num_features,512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(512,5)\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "UJHo_CCK9yp8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "n5FFC87H_3iZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "21bTzev9AG9E"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,dataloader,optimizer,epochs):\n",
        "  model.to(device)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss=0.0\n",
        "    for b, (X,y) in enumerate(dataloader):\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      y_pred = model(X)\n",
        "      loss = criterion(y_pred,y)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      running_loss += loss.item()\n",
        "\n",
        "      if (b + 1) % 10 == 0:  # every 10 batches\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Batch [{b+1}/{len(dataloader)}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(dataloader):.4f}\")\n",
        "\n",
        "    torch.save(model.state_dict(), f\"/content/drive/MyDrive/5_flower_classifier/checkpoint_epoch{epoch+1}.pth\")"
      ],
      "metadata": {
        "id": "LnHzGhxYAfwd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze layers\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "for param in model.fc.parameters():\n",
        "  param.requires_grad = True"
      ],
      "metadata": {
        "id": "726CL4JeA4uH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "\n",
        "train(model,train_loader,10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDHEFxdxB2OC",
        "outputId": "2b63c8a7-6dfc-46e8-bd94-ced5dc953d07"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Batch [10/108], Loss: 1.4902\n",
            "Epoch [1/10], Batch [20/108], Loss: 1.4364\n",
            "Epoch [1/10], Batch [30/108], Loss: 1.4419\n",
            "Epoch [1/10], Batch [40/108], Loss: 1.3703\n",
            "Epoch [1/10], Batch [50/108], Loss: 1.3034\n",
            "Epoch [1/10], Batch [60/108], Loss: 1.3282\n",
            "Epoch [1/10], Batch [70/108], Loss: 1.2384\n",
            "Epoch [1/10], Batch [80/108], Loss: 1.0835\n",
            "Epoch [1/10], Batch [90/108], Loss: 1.0814\n",
            "Epoch [1/10], Batch [100/108], Loss: 1.0015\n",
            "Epoch 1/10, Loss: 1.2851\n",
            "Epoch [2/10], Batch [10/108], Loss: 0.9819\n",
            "Epoch [2/10], Batch [20/108], Loss: 0.9627\n",
            "Epoch [2/10], Batch [30/108], Loss: 0.9339\n",
            "Epoch [2/10], Batch [40/108], Loss: 0.9072\n",
            "Epoch [2/10], Batch [50/108], Loss: 0.7377\n",
            "Epoch [2/10], Batch [60/108], Loss: 1.0210\n",
            "Epoch [2/10], Batch [70/108], Loss: 0.8086\n",
            "Epoch [2/10], Batch [80/108], Loss: 0.7543\n",
            "Epoch [2/10], Batch [90/108], Loss: 0.7076\n",
            "Epoch [2/10], Batch [100/108], Loss: 0.9515\n",
            "Epoch 2/10, Loss: 0.9426\n",
            "Epoch [3/10], Batch [10/108], Loss: 0.8406\n",
            "Epoch [3/10], Batch [20/108], Loss: 0.7380\n",
            "Epoch [3/10], Batch [30/108], Loss: 0.7922\n",
            "Epoch [3/10], Batch [40/108], Loss: 0.8669\n",
            "Epoch [3/10], Batch [50/108], Loss: 0.7921\n",
            "Epoch [3/10], Batch [60/108], Loss: 0.7566\n",
            "Epoch [3/10], Batch [70/108], Loss: 0.9083\n",
            "Epoch [3/10], Batch [80/108], Loss: 0.9090\n",
            "Epoch [3/10], Batch [90/108], Loss: 1.0008\n",
            "Epoch [3/10], Batch [100/108], Loss: 0.8352\n",
            "Epoch 3/10, Loss: 0.8357\n",
            "Epoch [4/10], Batch [10/108], Loss: 0.8266\n",
            "Epoch [4/10], Batch [20/108], Loss: 0.8152\n",
            "Epoch [4/10], Batch [30/108], Loss: 0.8229\n",
            "Epoch [4/10], Batch [40/108], Loss: 0.8420\n",
            "Epoch [4/10], Batch [50/108], Loss: 0.8339\n",
            "Epoch [4/10], Batch [60/108], Loss: 0.9544\n",
            "Epoch [4/10], Batch [70/108], Loss: 0.6225\n",
            "Epoch [4/10], Batch [80/108], Loss: 0.6463\n",
            "Epoch [4/10], Batch [90/108], Loss: 0.8127\n",
            "Epoch [4/10], Batch [100/108], Loss: 0.7762\n",
            "Epoch 4/10, Loss: 0.7830\n",
            "Epoch [5/10], Batch [10/108], Loss: 0.6886\n",
            "Epoch [5/10], Batch [20/108], Loss: 0.6384\n",
            "Epoch [5/10], Batch [30/108], Loss: 0.6372\n",
            "Epoch [5/10], Batch [40/108], Loss: 0.8426\n",
            "Epoch [5/10], Batch [50/108], Loss: 0.8145\n",
            "Epoch [5/10], Batch [60/108], Loss: 0.7406\n",
            "Epoch [5/10], Batch [70/108], Loss: 0.7747\n",
            "Epoch [5/10], Batch [80/108], Loss: 0.5366\n",
            "Epoch [5/10], Batch [90/108], Loss: 0.6452\n",
            "Epoch [5/10], Batch [100/108], Loss: 0.6910\n",
            "Epoch 5/10, Loss: 0.7338\n",
            "Epoch [6/10], Batch [10/108], Loss: 0.7328\n",
            "Epoch [6/10], Batch [20/108], Loss: 0.7953\n",
            "Epoch [6/10], Batch [30/108], Loss: 0.6555\n",
            "Epoch [6/10], Batch [40/108], Loss: 0.7524\n",
            "Epoch [6/10], Batch [50/108], Loss: 0.6198\n",
            "Epoch [6/10], Batch [60/108], Loss: 0.6392\n",
            "Epoch [6/10], Batch [70/108], Loss: 0.5665\n",
            "Epoch [6/10], Batch [80/108], Loss: 0.9880\n",
            "Epoch [6/10], Batch [90/108], Loss: 0.6445\n",
            "Epoch [6/10], Batch [100/108], Loss: 0.7533\n",
            "Epoch 6/10, Loss: 0.7127\n",
            "Epoch [7/10], Batch [10/108], Loss: 0.7332\n",
            "Epoch [7/10], Batch [20/108], Loss: 0.6354\n",
            "Epoch [7/10], Batch [30/108], Loss: 0.6025\n",
            "Epoch [7/10], Batch [40/108], Loss: 0.8299\n",
            "Epoch [7/10], Batch [50/108], Loss: 0.4365\n",
            "Epoch [7/10], Batch [60/108], Loss: 0.7195\n",
            "Epoch [7/10], Batch [70/108], Loss: 1.2834\n",
            "Epoch [7/10], Batch [80/108], Loss: 0.5724\n",
            "Epoch [7/10], Batch [90/108], Loss: 0.5029\n",
            "Epoch [7/10], Batch [100/108], Loss: 0.7317\n",
            "Epoch 7/10, Loss: 0.6868\n",
            "Epoch [8/10], Batch [10/108], Loss: 1.1393\n",
            "Epoch [8/10], Batch [20/108], Loss: 0.4287\n",
            "Epoch [8/10], Batch [30/108], Loss: 0.9259\n",
            "Epoch [8/10], Batch [40/108], Loss: 0.5984\n",
            "Epoch [8/10], Batch [50/108], Loss: 0.7373\n",
            "Epoch [8/10], Batch [60/108], Loss: 0.6153\n",
            "Epoch [8/10], Batch [70/108], Loss: 0.4866\n",
            "Epoch [8/10], Batch [80/108], Loss: 0.7774\n",
            "Epoch [8/10], Batch [90/108], Loss: 0.6655\n",
            "Epoch [8/10], Batch [100/108], Loss: 0.6943\n",
            "Epoch 8/10, Loss: 0.6964\n",
            "Epoch [9/10], Batch [10/108], Loss: 0.5384\n",
            "Epoch [9/10], Batch [20/108], Loss: 0.6449\n",
            "Epoch [9/10], Batch [30/108], Loss: 0.4450\n",
            "Epoch [9/10], Batch [40/108], Loss: 0.5722\n",
            "Epoch [9/10], Batch [50/108], Loss: 0.6992\n",
            "Epoch [9/10], Batch [60/108], Loss: 0.7943\n",
            "Epoch [9/10], Batch [70/108], Loss: 0.9082\n",
            "Epoch [9/10], Batch [80/108], Loss: 0.6570\n",
            "Epoch [9/10], Batch [90/108], Loss: 0.8994\n",
            "Epoch [9/10], Batch [100/108], Loss: 0.8857\n",
            "Epoch 9/10, Loss: 0.6816\n",
            "Epoch [10/10], Batch [10/108], Loss: 0.8086\n",
            "Epoch [10/10], Batch [20/108], Loss: 0.6706\n",
            "Epoch [10/10], Batch [30/108], Loss: 0.5766\n",
            "Epoch [10/10], Batch [40/108], Loss: 0.9113\n",
            "Epoch [10/10], Batch [50/108], Loss: 0.7584\n",
            "Epoch [10/10], Batch [60/108], Loss: 0.6133\n",
            "Epoch [10/10], Batch [70/108], Loss: 0.7450\n",
            "Epoch [10/10], Batch [80/108], Loss: 0.9661\n",
            "Epoch [10/10], Batch [90/108], Loss: 0.5580\n",
            "Epoch [10/10], Batch [100/108], Loss: 0.5895\n",
            "Epoch 10/10, Loss: 0.6855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/5_flower_classifier/first_model.pth\")"
      ],
      "metadata": {
        "id": "2gHc_rD-B-A9"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "current_model = models.resnet50(pretrained=False)\n",
        "num_features = current_model.fc.in_features\n",
        "current_model.fc = nn.Sequential(\n",
        "    nn.Linear(num_features, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(512, 5)\n",
        ")\n",
        "\n",
        "current_model.load_state_dict(torch.load(\"/content/drive/MyDrive/5_flower_classifier/first_model.pth\"))\n",
        "current_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UTwVzkBEkbu",
        "outputId": "4409d74d-b74c-474f-b7b9-7bb305c5130a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=512, out_features=5, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Bring the flower labels in\n",
        "flowers = train_dataset.classes\n",
        "flowers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "xkvXJAYJI61W",
        "outputId": "73103f0b-58a7-4d9f-af4b-a6293a014ed3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-471629778.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Bring the flower labels in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mflowers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mflowers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model,loader,criterion,device):\n",
        "  model.eval()\n",
        "  running_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  max_batches = 20\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i, (X, y) in enumerate(loader):\n",
        "\n",
        "      X,y = X.to(device), y.to(device)\n",
        "\n",
        "      outputs = model(X)\n",
        "      loss = criterion(outputs,y)\n",
        "      running_loss += loss.item()\n",
        "\n",
        "      #predictions\n",
        "      _, preds = torch.max(outputs,1)\n",
        "      correct += (preds == y).sum().item()\n",
        "      total += y.size(0)\n",
        "\n",
        "  avg_loss = running_loss / len(loader)\n",
        "  accuracy = 100 * correct / total\n",
        "  print(f\"Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "  return avg_loss, accuracy\n"
      ],
      "metadata": {
        "id": "sAZC-IOFJG7h"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(current_model, test_loader, criterion,device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DI6WT46yJs_6",
        "outputId": "49f889c9-d8ae-4594-99c5-d8308107f2ed"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4065, Accuracy: 84.16%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4064834235302572, 84.16184971098266)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model,X,device,class_name):\n",
        "  with torch.no_grad():\n",
        "\n",
        "    model.eval()\n",
        "    output = model(X)\n",
        "    _,preds = torch.max(output,1)\n",
        "    return flowers[preds]\n",
        "\n"
      ],
      "metadata": {
        "id": "LTLqlED6KAn9"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/5_flower_classifier/sunflower3.jpg\"\n",
        "image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "# transform setting to image\n",
        "t_img = test_transform(image)\n",
        "# Add batch dimensions\n",
        "test_img = t_img.unsqueeze(0).to(device)\n",
        "\n",
        "pred_name = predict(current_model, test_img, device, flowers)\n",
        "\n",
        "print(f\"Predicted: {pred_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuP1IbO3Lmak",
        "outputId": "cccbe0a9-e775-4cc7-b7a8-34784d54d76f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: sunflower\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform further training to see if we can get it a little more accurate\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer2 = torch.optim.Adam([\n",
        "    {'params': current_model.layer4.parameters(), 'lr': 1e-4},\n",
        "    {'params': current_model.fc.parameters(), 'lr': 1e-3}\n",
        "])\n",
        "\n",
        "for param in current_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in current_model.layer4.parameters():  # unfreeze last block\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in current_model.fc.parameters():  # ensure classifier is trainable\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "4gZ8aWH4MmGQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(current_model,train_loader,optimizer2,5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThH3FrPuSqkr",
        "outputId": "1637b2c5-13a9-4621-fd11-eeb873f00723"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Batch [10/108], Loss: 0.9644\n",
            "Epoch [1/5], Batch [20/108], Loss: 0.5550\n",
            "Epoch [1/5], Batch [30/108], Loss: 0.9210\n",
            "Epoch [1/5], Batch [40/108], Loss: 0.6496\n",
            "Epoch [1/5], Batch [50/108], Loss: 0.6486\n",
            "Epoch [1/5], Batch [60/108], Loss: 0.5866\n",
            "Epoch [1/5], Batch [70/108], Loss: 0.5689\n",
            "Epoch [1/5], Batch [80/108], Loss: 0.7999\n",
            "Epoch [1/5], Batch [90/108], Loss: 0.4287\n",
            "Epoch [1/5], Batch [100/108], Loss: 0.3820\n",
            "Epoch 1/5, Loss: 0.7003\n",
            "Epoch [2/5], Batch [10/108], Loss: 0.2586\n",
            "Epoch [2/5], Batch [20/108], Loss: 0.6055\n",
            "Epoch [2/5], Batch [30/108], Loss: 0.6458\n",
            "Epoch [2/5], Batch [40/108], Loss: 0.9930\n",
            "Epoch [2/5], Batch [50/108], Loss: 0.4249\n",
            "Epoch [2/5], Batch [60/108], Loss: 0.4411\n",
            "Epoch [2/5], Batch [70/108], Loss: 0.7283\n",
            "Epoch [2/5], Batch [80/108], Loss: 0.5875\n",
            "Epoch [2/5], Batch [90/108], Loss: 0.6342\n",
            "Epoch [2/5], Batch [100/108], Loss: 0.3410\n",
            "Epoch 2/5, Loss: 0.5766\n",
            "Epoch [3/5], Batch [10/108], Loss: 0.4590\n",
            "Epoch [3/5], Batch [20/108], Loss: 0.4996\n",
            "Epoch [3/5], Batch [30/108], Loss: 0.3897\n",
            "Epoch [3/5], Batch [40/108], Loss: 0.5245\n",
            "Epoch [3/5], Batch [50/108], Loss: 0.5068\n",
            "Epoch [3/5], Batch [60/108], Loss: 0.5817\n",
            "Epoch [3/5], Batch [70/108], Loss: 0.3526\n",
            "Epoch [3/5], Batch [80/108], Loss: 0.6839\n",
            "Epoch [3/5], Batch [90/108], Loss: 0.4593\n",
            "Epoch [3/5], Batch [100/108], Loss: 0.2975\n",
            "Epoch 3/5, Loss: 0.5224\n",
            "Epoch [4/5], Batch [10/108], Loss: 0.4422\n",
            "Epoch [4/5], Batch [20/108], Loss: 0.6188\n",
            "Epoch [4/5], Batch [30/108], Loss: 0.4778\n",
            "Epoch [4/5], Batch [40/108], Loss: 0.5733\n",
            "Epoch [4/5], Batch [50/108], Loss: 0.3873\n",
            "Epoch [4/5], Batch [60/108], Loss: 0.4912\n",
            "Epoch [4/5], Batch [70/108], Loss: 0.1986\n",
            "Epoch [4/5], Batch [80/108], Loss: 0.5669\n",
            "Epoch [4/5], Batch [90/108], Loss: 0.3021\n",
            "Epoch [4/5], Batch [100/108], Loss: 0.5761\n",
            "Epoch 4/5, Loss: 0.4522\n",
            "Epoch [5/5], Batch [10/108], Loss: 0.5165\n",
            "Epoch [5/5], Batch [20/108], Loss: 0.4627\n",
            "Epoch [5/5], Batch [30/108], Loss: 0.5463\n",
            "Epoch [5/5], Batch [40/108], Loss: 0.4884\n",
            "Epoch [5/5], Batch [50/108], Loss: 0.3590\n",
            "Epoch [5/5], Batch [60/108], Loss: 0.3375\n",
            "Epoch [5/5], Batch [70/108], Loss: 0.5829\n",
            "Epoch [5/5], Batch [80/108], Loss: 0.3700\n",
            "Epoch [5/5], Batch [90/108], Loss: 0.2059\n",
            "Epoch [5/5], Batch [100/108], Loss: 0.4257\n",
            "Epoch 5/5, Loss: 0.4668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(current_model, test_loader, criterion,device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvjr8SiDUAHG",
        "outputId": "c06d5f64-a7bd-48c1-ec27-219f870f8531"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2205, Accuracy: 90.98%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.22049897097534604, 90.98265895953757)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Best model so far\n",
        "torch.save(current_model.state_dict(), \"/content/drive/MyDrive/5_flower_classifier/best_model.pth\")"
      ],
      "metadata": {
        "id": "ANOyjgwraXvu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HVMHgrQhbsli"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}